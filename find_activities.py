"""
æ´»å‹•è¨˜éŒ„æŸ¥æ‰¾å’Œå ±å‘Šç”Ÿæˆå·¥å…·
è‡ªå‹•ç™»å…¥ã€æƒæ ticketã€è¨˜éŒ„æ´»å‹•ä¸¦ç”Ÿæˆå ±å‘Š
"""

import time
import logging
import json
import csv
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import config
import getpass
import os
import glob

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ActivityScanner:
    """æ´»å‹•æƒæå™¨"""
    
    def __init__(self):
        self.driver = None
        self.wait = None
        self.activities = []
        
    def setup_driver(self):
        """è¨­å®šç€è¦½å™¨"""
        try:
            chrome_options = Options()
            chrome_options.add_argument("--window-size=1920,1080")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.wait = WebDriverWait(self.driver, 10)
            logger.info("ç€è¦½å™¨å·²å•Ÿå‹•")
            
        except Exception as e:
            logger.error(f"å•Ÿå‹•ç€è¦½å™¨å¤±æ•—: {e}")
            raise
    
    def close_driver(self):
        """é—œé–‰ç€è¦½å™¨"""
        if self.driver:
            try:
                self.driver.quit()
                logger.info("ç€è¦½å™¨å·²é—œé–‰")
            except Exception as e:
                logger.warning(f"é—œé–‰ç€è¦½å™¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    
    def login_to_eservice(self, username, password):
        """ç™»å…¥ eService"""
        try:
            print("ğŸ” æ­£åœ¨ç™»å…¥ eService...")
            
            # ä½¿ç”¨ç¾æœ‰çš„ç™»å…¥é‚è¼¯
            from browser_automation import BrowserAutomation
            browser = BrowserAutomation()
            browser.driver = self.driver
            browser.wait = self.wait
            
            login_success = browser.login_to_website(config.ESERVICE_CONFIG, username, password)
            
            if login_success:
                print("âœ… ç™»å…¥æˆåŠŸï¼")
                return True
            else:
                print("âŒ ç™»å…¥å¤±æ•—")
                return False
                
        except Exception as e:
            logger.error(f"ç™»å…¥å¤±æ•—: {e}")
            return False
    
    def analyze_dashboard_structure(self):
        """åˆ†æ Dashboard çµæ§‹"""
        try:
            print("\nğŸ” åˆ†æ Dashboard çµæ§‹...")
            
            current_url = self.driver.current_url
            page_title = self.driver.title
            print(f"ğŸ“ ç•¶å‰ URL: {current_url}")
            print(f"ğŸ“„ é é¢æ¨™é¡Œ: {page_title}")
            
            # ç­‰å¾…é é¢è¼‰å…¥
            time.sleep(3)
            
            page_source = self.driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            
            # å°‹æ‰¾å¯èƒ½çš„ ticket å®¹å™¨
            ticket_selectors = [
                '.ticket', '.tickets', '.ticket-list', '.issue', '.issues', '.issue-list',
                '.conversation', '.conversations', '.message', '.messages',
                '.dashboard', '.dashboard-content', '.recent', '.recent-activity',
                '.timeline', '.feed', '.news', '.updates',
                '.my-tickets', '.my-issues', '.assigned-to-me',
                '.created-by-me', '.reported-by-me',
                '.table', '.list', '.grid', '.items',
                '[data-ticket-id]', '[data-issue-id]', '[data-conversation-id]'
            ]
            
            found_containers = []
            for selector in ticket_selectors:
                elements = soup.select(selector)
                if elements:
                    print(f"âœ… æ‰¾åˆ° {len(elements)} å€‹å…ƒç´ : {selector}")
                    found_containers.append({
                        'selector': selector,
                        'count': len(elements),
                        'elements': elements[:5]  # åªå–å‰5å€‹ä½œç‚ºæ¨£æœ¬
                    })
            
            # å°‹æ‰¾è¡¨æ ¼å’Œåˆ—è¡¨
            tables = soup.find_all('table')
            lists = soup.find_all(['ul', 'ol'])
            
            print(f"ğŸ“Š æ‰¾åˆ° {len(tables)} å€‹è¡¨æ ¼")
            print(f"ğŸ“‹ æ‰¾åˆ° {len(lists)} å€‹åˆ—è¡¨")
            
            # åˆ†æç¬¬ä¸€å€‹è¡¨æ ¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if tables:
                print("\nğŸ“Š åˆ†æç¬¬ä¸€å€‹è¡¨æ ¼çµæ§‹:")
                first_table = tables[0]
                rows = first_table.find_all('tr')
                print(f"   è¡Œæ•¸: {len(rows)}")
                
                if rows:
                    headers = rows[0].find_all(['th', 'td'])
                    print(f"   åˆ—æ•¸: {len(headers)}")
                    print("   æ¨™é¡Œ:")
                    for i, header in enumerate(headers[:5]):  # åªé¡¯ç¤ºå‰5åˆ—
                        header_text = header.get_text(strip=True)
                        print(f"     åˆ— {i+1}: {header_text}")
            
            return found_containers
            
        except Exception as e:
            logger.error(f"åˆ†æ Dashboard çµæ§‹å¤±æ•—: {e}")
            return []
    
    def find_ticket_elements(self):
        """å°‹æ‰¾ ticket å…ƒç´ """
        try:
            print("\nğŸ” å°‹æ‰¾ ticket å…ƒç´ ...")
            
            # ç­‰å¾…é é¢è¼‰å…¥
            time.sleep(2)
            
            page_source = self.driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            
            # å˜—è©¦å¤šç¨®é¸æ“‡å™¨ä¾†æ‰¾åˆ° ticket
            ticket_selectors = [
                'tr[data-ticket-id]', 'tr[data-issue-id]',
                '.ticket-item', '.issue-item', '.conversation-item',
                '.ticket-row', '.issue-row',
                'tr:has(td)', 'li:has(a)',
                '.item', '.entry', '.record'
            ]
            
            found_tickets = []
            for selector in ticket_selectors:
                try:
                    elements = soup.select(selector)
                    if elements:
                        print(f"âœ… ä½¿ç”¨é¸æ“‡å™¨ '{selector}' æ‰¾åˆ° {len(elements)} å€‹ ticket")
                        found_tickets.extend(elements[:50])  # é™åˆ¶ç‚ºå‰50å€‹
                        break
                except Exception as e:
                    continue
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°ï¼Œå˜—è©¦æ›´é€šç”¨çš„æ–¹æ³•
            if not found_tickets:
                print("âš ï¸  ä½¿ç”¨é€šç”¨æ–¹æ³•å°‹æ‰¾ ticket...")
                
                # å°‹æ‰¾åŒ…å«æ—¥æœŸçš„è¡Œ
                date_patterns = ['2024', '2023', '2025', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
                
                for pattern in date_patterns:
                    elements = soup.find_all(text=lambda text: text and pattern in text)
                    if elements:
                        for element in elements:
                            parent = element.parent
                            if parent and parent.name in ['tr', 'li', 'div']:
                                found_tickets.append(parent)
                                if len(found_tickets) >= 50:
                                    break
                        if len(found_tickets) >= 50:
                            break
            
            print(f"ğŸ“‹ ç¸½å…±æ‰¾åˆ° {len(found_tickets)} å€‹å¯èƒ½çš„ ticket")
            return found_tickets[:50]  # é™åˆ¶ç‚º50å€‹
            
        except Exception as e:
            logger.error(f"å°‹æ‰¾ ticket å…ƒç´ å¤±æ•—: {e}")
            return []
    
    def extract_ticket_info(self, ticket_element):
        """æå–å–®å€‹ ticket ä¿¡æ¯"""
        try:
            ticket_info = {
                'id': '',
                'title': '',
                'date': '',
                'status': '',
                'content': '',
                'url': '',
                'full_url': '',
                'source': 'eservice',
                'raw_text': ticket_element.get_text(strip=True)[:500],  # ä¿å­˜åŸå§‹æ–‡æœ¬ç”¨æ–¼èª¿è©¦
                'detailed_interactions': []  # è©³ç´°äº’å‹•å…§å®¹
            }
            
            # æå– ID
            ticket_id = ticket_element.get('data-ticket-id') or ticket_element.get('data-issue-id')
            if ticket_id:
                ticket_info['id'] = ticket_id
            
            # æå–æ¨™é¡Œ - å˜—è©¦å¤šç¨®æ–¹æ³•
            title_element = ticket_element.find(['h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'a', 'span', 'div'])
            if title_element:
                ticket_info['title'] = title_element.get_text(strip=True)
            
            # æå–æ—¥æœŸ - æ”¹é€²çš„æ—¥æœŸæå–
            date_patterns = [
                '2024', '2023', '2025',  # å¹´ä»½
                'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec',  # è‹±æ–‡æœˆä»½
                'hours ago', 'days ago', 'minutes ago', 'ago',  # ç›¸å°æ™‚é–“
                'today', 'yesterday',  # ç›¸å°æ—¥æœŸ
                'åˆ†é˜å‰', 'å°æ™‚å‰', 'å¤©å‰'  # ä¸­æ–‡ç›¸å°æ™‚é–“
            ]
            
            for pattern in date_patterns:
                date_elements = ticket_element.find_all(string=lambda text: text and pattern in text)
                if date_elements:
                    ticket_info['date'] = date_elements[0].strip()
                    break
            
            # æå–ç‹€æ…‹ - æ”¹é€²çš„ç‹€æ…‹æå–
            status_keywords = ['open', 'closed', 'pending', 'resolved', 'active', 'inactive', 'new', 'old', 'high', 'low', 'medium']
            for keyword in status_keywords:
                status_elements = ticket_element.find_all(string=lambda text: text and keyword.lower() in text.lower())
                if status_elements:
                    ticket_info['status'] = status_elements[0].strip()
                    break
            
            # æå–å…§å®¹
            content_element = ticket_element.find(['p', 'div', 'span'])
            if content_element:
                ticket_info['content'] = content_element.get_text(strip=True)[:200]
            
            # æå– URL
            link_element = ticket_element.find('a', href=True)
            if link_element:
                ticket_info['url'] = link_element.get('href')
                # æ§‹å»ºå®Œæ•´ URL
                if ticket_info['url'] and not ticket_info['url'].startswith('http'):
                    ticket_info['full_url'] = config.ESERVICE_CONFIG['original_url'] + ticket_info['url']
                else:
                    ticket_info['full_url'] = ticket_info['url']
            
            return ticket_info
            
        except Exception as e:
            logger.warning(f"æå– ticket ä¿¡æ¯å¤±æ•—: {e}")
            return None
    
    def check_activity_within_days(self, ticket_info, days=10):
        """æª¢æŸ¥æ´»å‹•æ˜¯å¦åœ¨æŒ‡å®šå¤©æ•¸å…§"""
        try:
            if not ticket_info.get('date'):
                return False
            
            date_str = ticket_info['date']
            
            # è™•ç†ç›¸å°æ™‚é–“
            if 'hours ago' in date_str.lower():
                return True  # å¹¾å°æ™‚å‰è‚¯å®šåœ¨10å¤©å…§
            elif 'days ago' in date_str.lower():
                # æå–å¤©æ•¸
                import re
                match = re.search(r'(\d+)\s*days?\s*ago', date_str.lower())
                if match:
                    days_ago = int(match.group(1))
                    return days_ago <= days
                return True  # å¦‚æœç„¡æ³•è§£æï¼Œå‡è¨­åœ¨ç¯„åœå…§
            elif 'minutes ago' in date_str.lower():
                return True  # å¹¾åˆ†é˜å‰è‚¯å®šåœ¨10å¤©å…§
            elif 'today' in date_str.lower() or 'yesterday' in date_str.lower():
                return True
            elif 'åˆ†é˜å‰' in date_str or 'å°æ™‚å‰' in date_str or 'å¤©å‰' in date_str:
                return True
            
            # å˜—è©¦è§£æå…·é«”æ—¥æœŸ
            date_formats = [
                "%Y-%m-%d", "%Y/%m/%d", "%m/%d/%Y", "%d/%m/%Y",
                "%Yå¹´%mæœˆ%dæ—¥", "%mæœˆ%dæ—¥", "%dæ—¥%mæœˆ%Yå¹´"
            ]
            
            for fmt in date_formats:
                try:
                    parsed_date = datetime.strptime(date_str, fmt)
                    days_diff = (datetime.now() - parsed_date).days
                    return days_diff <= days
                except ValueError:
                    continue
            
            # å¦‚æœéƒ½ç„¡æ³•è§£æï¼Œæª¢æŸ¥æ˜¯å¦åŒ…å«ç›¸å°æ™‚é–“è©
            relative_time_keywords = ['ago', 'å‰']
            for keyword in relative_time_keywords:
                if keyword.lower() in date_str.lower():
                    return True
            
            return False
            
        except Exception as e:
            logger.warning(f"æª¢æŸ¥æ—¥æœŸå¤±æ•—: {e}")
            return False
    
    def extract_conversation_content(self, conversation_element):
        """æå–å°è©±å…§å®¹å€åŸŸçš„æ‰€æœ‰æ–‡å­—"""
        try:
            if not conversation_element:
                return ""
            
            # ä½¿ç”¨æ¨¹ç‹€éæ­·æ–¹æ³•æå–æ‰€æœ‰æ–‡å­—å…§å®¹
            text_content = ""
            
            # éæ­·æ‰€æœ‰å­å…ƒç´ å’Œæ–‡å­—ç¯€é»
            for element in conversation_element.descendants:
                if element.name is None:  # æ–‡å­—ç¯€é»
                    text = element.strip()
                    if text:
                        text_content += text + " "
                elif element.name in ['br']:  # æ›è¡Œæ¨™ç±¤
                    text_content += "\n"
                elif element.name in ['p', 'div'] and element.get_text(strip=True):
                    # å°æ–¼æ®µè½å’Œ divï¼Œæ·»åŠ é¡å¤–çš„æ›è¡Œ
                    text_content += "\n"
            
            # æ¸…ç†å¤šé¤˜çš„ç©ºç™½å­—ç¬¦ï¼Œä½†ä¿ç•™æ›è¡Œ
            lines = text_content.split('\n')
            cleaned_lines = []
            for line in lines:
                cleaned_line = ' '.join(line.split())
                if cleaned_line:
                    cleaned_lines.append(cleaned_line)
            
            return '\n'.join(cleaned_lines)
            
        except Exception as e:
            logger.warning(f"æå–å°è©±å…§å®¹å¤±æ•—: {e}")
            return conversation_element.get_text(strip=True) if conversation_element else ""
    
    def extract_ltr_content(self, ltr_div):
        """æå– <div dir="ltr"> æ¨™ç±¤å…§çš„å®Œæ•´æ–‡å­—å…§å®¹"""
        try:
            if not ltr_div:
                return ""
            
            # ç²å–æ‰€æœ‰æ–‡å­—å…§å®¹ï¼ŒåŒ…æ‹¬åµŒå¥—çš„ div å’Œ span
            text_content = ""
            
            # éæ­·æ‰€æœ‰å­å…ƒç´ 
            for element in ltr_div.descendants:
                if element.name is None:  # æ–‡å­—ç¯€é»
                    text = element.strip()
                    if text:
                        text_content += text + " "
                elif element.name in ['br']:  # æ›è¡Œæ¨™ç±¤
                    text_content += "\n"
            
            # æ¸…ç†å¤šé¤˜çš„ç©ºç™½å­—ç¬¦
            text_content = ' '.join(text_content.split())
            return text_content
            
        except Exception as e:
            logger.warning(f"æå– LTR å…§å®¹å¤±æ•—: {e}")
            return ltr_div.get_text(strip=True) if ltr_div else ""
    
    def extract_jira_links(self, text_content):
        """æå– Jira é€£çµä¸­çš„æœ‰æ„ç¾©å…§å®¹"""
        try:
            import re
            jira_info = []
            
            # å°‹æ‰¾ Jira é€£çµæ¨¡å¼
            jira_patterns = [
                r'https://ticket\.quectel\.com/browse/([A-Z]+-\d+)',  # å®Œæ•´ URL
                r'#([A-Z]+-\d+)',  # é¡Œè™Ÿæ ¼å¼
                r'([A-Z]+-\d+)'    # ä¸€èˆ¬é¡Œè™Ÿ
            ]
            
            for pattern in jira_patterns:
                matches = re.findall(pattern, text_content)
                for match in matches:
                    if match not in [info['ticket_id'] for info in jira_info]:
                        jira_info.append({
                            'ticket_id': match,
                            'full_url': f"https://ticket.quectel.com/browse/{match}",
                            'context': text_content[:200] + "..." if len(text_content) > 200 else text_content
                        })
            
            return jira_info
            
        except Exception as e:
            logger.warning(f"æå– Jira é€£çµå¤±æ•—: {e}")
            return []
    
    def get_ticket_detailed_interactions(self, ticket_info):
        """ç²å– ticket çš„è©³ç´°äº’å‹•å…§å®¹"""
        try:
            if not ticket_info.get('full_url'):
                logger.warning(f"ç„¡æ³•ç²å–è©³ç´°å…§å®¹ï¼šç¼ºå°‘å®Œæ•´ URL")
                return []
            
            print(f"  ğŸ” ç²å–è©³ç´°å…§å®¹: {ticket_info['full_url']}")
            
            # å°èˆªåˆ° ticket è©³ç´°é é¢
            self.driver.get(ticket_info['full_url'])
            time.sleep(3)
            
            # ç­‰å¾…é é¢è¼‰å…¥
            try:
                self.wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
            except TimeoutException:
                logger.warning(f"é é¢è¼‰å…¥è¶…æ™‚: {ticket_info['full_url']}")
                return []
            
            # è§£æé é¢å…§å®¹
            page_source = self.driver.page_source
            soup = BeautifulSoup(page_source, 'html.parser')
            
            interactions = []
            
            # ä½¿ç”¨æ–°çš„ç­–ç•¥ï¼šå°‹æ‰¾å°è©±å…§å®¹å®¹å™¨
            conversation_containers = soup.find_all('div', class_='ticket-details__conversation__content')
            print(f"  ğŸ“ æ‰¾åˆ° {len(conversation_containers)} å€‹å°è©±å…§å®¹å®¹å™¨")
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°å°è©±å®¹å™¨ï¼Œå˜—è©¦å…¶ä»–é¸æ“‡å™¨
            if not conversation_containers:
                conversation_containers = soup.find_all('div', attrs={'data-test-id': 'conversation-content'})
                print(f"  ğŸ“ ä½¿ç”¨ data-test-id æ‰¾åˆ° {len(conversation_containers)} å€‹å°è©±å…§å®¹å®¹å™¨")
            
            # å¦‚æœé‚„æ˜¯æ²’æœ‰æ‰¾åˆ°ï¼Œå˜—è©¦æ›´é€šç”¨çš„æ–¹æ³•
            if not conversation_containers:
                conversation_containers = soup.find_all('div', class_='conversation-content')
                print(f"  ğŸ“ ä½¿ç”¨é€šç”¨é¸æ“‡å™¨æ‰¾åˆ° {len(conversation_containers)} å€‹å°è©±å…§å®¹å®¹å™¨")
            
            # è™•ç†æ¯å€‹å°è©±å®¹å™¨
            for i, conversation_container in enumerate(conversation_containers[:10]):  # é™åˆ¶ç‚ºå‰10å€‹
                try:
                    # å°‹æ‰¾ç›¸é—œçš„æ™‚é–“æˆ³å’Œä½œè€…ä¿¡æ¯
                    timestamp = ''
                    author = ''
                    
                    # åœ¨å°è©±å®¹å™¨çš„çˆ¶ç´šæˆ–å…„å¼Ÿå…ƒç´ ä¸­å°‹æ‰¾æ™‚é–“æˆ³å’Œä½œè€…
                    parent_container = conversation_container.parent
                    if parent_container:
                        # å°‹æ‰¾æ™‚é–“æˆ³
                        time_patterns = ['ago', 'å‰', 'hours', 'days', 'minutes', 'å°æ™‚', 'å¤©', 'åˆ†é˜']
                        for pattern in time_patterns:
                            time_elements = parent_container.find_all(string=lambda text: text and pattern in text)
                            if time_elements:
                                timestamp = time_elements[0].strip()
                                break
                        
                        # å°‹æ‰¾ä½œè€…ä¿¡æ¯
                        author_selectors = ['.author', '.user', '.name', '.username', '.by', '[data-test-id="user-name"]']
                        for selector in author_selectors:
                            author_element = parent_container.select_one(selector)
                            if author_element:
                                author = author_element.get_text(strip=True)
                                break
                    
                    # æå–å°è©±å…§å®¹
                    conversation_content = self.extract_conversation_content(conversation_container)
                    
                    # æå– Jira é€£çµ
                    jira_links = self.extract_jira_links(conversation_content)
                    
                    # åˆ¤æ–·äº’å‹•é¡å‹
                    interaction_type = 'response'
                    if conversation_content:
                        content_lower = conversation_content.lower()
                        if 'customer' in content_lower or 'å®¢æˆ¶' in content_lower:
                            interaction_type = 'customer_response'
                        elif 'agent' in content_lower or 'agent responded' in content_lower:
                            interaction_type = 'agent_response'
                        elif 'created' in content_lower or 'opened' in content_lower:
                            interaction_type = 'ticket_created'
                        elif 'closed' in content_lower or 'resolved' in content_lower:
                            interaction_type = 'ticket_closed'
                    
                    interaction_info = {
                        'timestamp': timestamp,
                        'author': author,
                        'content': conversation_content[:300],
                        'type': interaction_type,
                        'ltr_content': conversation_content[:2000],  # å¢åŠ é•·åº¦é™åˆ¶
                        'jira_links': jira_links
                    }
                    
                    interactions.append(interaction_info)
                    print(f"    ğŸ“ å°è©± {i+1}: {conversation_content[:100]}...")
                    if jira_links:
                        print(f"    ğŸ”— æ‰¾åˆ° Jira é€£çµ: {[link['ticket_id'] for link in jira_links]}")
                
                except Exception as e:
                    logger.warning(f"è™•ç†å°è©±å®¹å™¨å¤±æ•—: {e}")
                    continue
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°å°è©±å®¹å™¨ï¼Œå›é€€åˆ°èˆŠçš„ LTR æ–¹æ³•
            if not interactions:
                print(f"  ğŸ”„ å›é€€åˆ° LTR æ–¹æ³•...")
                ltr_divs = soup.find_all('div', attrs={'dir': 'ltr'})
                print(f"  ğŸ“ æ‰¾åˆ° {len(ltr_divs)} å€‹ <div dir='ltr'> æ¨™ç±¤")
                
                for i, ltr_div in enumerate(ltr_divs[:10]):  # é™åˆ¶ç‚ºå‰10å€‹
                    try:
                        # å°‹æ‰¾ç›¸é—œçš„æ™‚é–“æˆ³ï¼ˆåœ¨ ltr_div é™„è¿‘ï¼‰
                        parent_container = ltr_div.parent
                        timestamp = ''
                        
                        # åœ¨çˆ¶å®¹å™¨ä¸­å°‹æ‰¾æ™‚é–“æˆ³
                        time_patterns = ['ago', 'å‰', 'hours', 'days', 'minutes', 'å°æ™‚', 'å¤©', 'åˆ†é˜']
                        for pattern in time_patterns:
                            time_elements = parent_container.find_all(string=lambda text: text and pattern in text)
                            if time_elements:
                                timestamp = time_elements[0].strip()
                                break
                        
                        # å°‹æ‰¾ä½œè€…ä¿¡æ¯
                        author = ''
                        author_selectors = ['.author', '.user', '.name', '.username', '.by']
                        for selector in author_selectors:
                            author_element = parent_container.select_one(selector)
                            if author_element:
                                author = author_element.get_text(strip=True)
                                break
                        
                        # æå– LTR å…§å®¹
                        ltr_content = self.extract_ltr_content(ltr_div)
                        jira_links = self.extract_jira_links(ltr_content)
                        
                        interaction_info = {
                            'timestamp': timestamp,
                            'author': author,
                            'content': ltr_content[:300],
                            'type': 'response',
                            'ltr_content': ltr_content[:1000],
                            'jira_links': jira_links
                        }
                        
                        interactions.append(interaction_info)
                        print(f"    ğŸ“ LTR {i+1}: {ltr_content[:100]}...")
                        if jira_links:
                            print(f"    ğŸ”— æ‰¾åˆ° Jira é€£çµ: {[link['ticket_id'] for link in jira_links]}")
                    
                    except Exception as e:
                        logger.warning(f"è™•ç† LTR div å¤±æ•—: {e}")
                        continue
            
            print(f"  âœ… æ‰¾åˆ° {len(interactions)} å€‹äº’å‹•è¨˜éŒ„")
            return interactions
            
        except Exception as e:
            logger.error(f"ç²å–è©³ç´°äº’å‹•å…§å®¹å¤±æ•—: {e}")
            return []
    
    def scan_tickets_and_generate_report(self, username, password, days_back=10, max_tickets=50):
        """æƒæ tickets ä¸¦ç”Ÿæˆå ±å‘Š"""
        try:
            print(f"ğŸš€ é–‹å§‹æƒæ eService tickets...")
            print(f"ğŸ“… æƒæç¯„åœ: éå» {days_back} å¤©")
            print(f"ğŸ“Š æœ€å¤§æƒææ•¸é‡: {max_tickets} å€‹ tickets")
            print()
            
            # è¨­å®šç€è¦½å™¨
            self.setup_driver()
            
            # ç™»å…¥
            if not self.login_to_eservice(username, password):
                return False
            
            # åˆ†æ Dashboard çµæ§‹
            containers = self.analyze_dashboard_structure()
            
            # å°‹æ‰¾ ticket å…ƒç´ 
            ticket_elements = self.find_ticket_elements()
            
            if not ticket_elements:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½• ticket å…ƒç´ ")
                return False
            
            print(f"\nğŸ“‹ é–‹å§‹æå– {len(ticket_elements)} å€‹ tickets çš„ä¿¡æ¯...")
            
            # æå– ticket ä¿¡æ¯
            all_tickets = []
            recent_activities = []
            
            for i, ticket_element in enumerate(ticket_elements):
                print(f"è™•ç† ticket {i+1}/{len(ticket_elements)}...")
                
                ticket_info = self.extract_ticket_info(ticket_element)
                if ticket_info:
                    all_tickets.append(ticket_info)
                    
                    # èª¿è©¦ï¼šé¡¯ç¤ºæå–çš„ä¿¡æ¯
                    print(f"  ğŸ“‹ æ¨™é¡Œ: {ticket_info.get('title', 'N/A')[:50]}...")
                    print(f"  ğŸ“… æ—¥æœŸ: {ticket_info.get('date', 'N/A')}")
                    print(f"  ğŸ“Š ç‹€æ…‹: {ticket_info.get('status', 'N/A')}")
                    
                    # æª¢æŸ¥æ˜¯å¦åœ¨æŒ‡å®šå¤©æ•¸å…§
                    is_recent = self.check_activity_within_days(ticket_info, days_back)
                    if is_recent:
                        # ç²å–è©³ç´°äº’å‹•å…§å®¹
                        detailed_interactions = self.get_ticket_detailed_interactions(ticket_info)
                        ticket_info['detailed_interactions'] = detailed_interactions
                        
                        recent_activities.append(ticket_info)
                        print(f"  âœ… æ‰¾åˆ°æœ€è¿‘æ´»å‹•: {ticket_info.get('title', 'N/A')}")
                        print(f"  ğŸ’¬ è©³ç´°äº’å‹•: {len(detailed_interactions)} å€‹è¨˜éŒ„")
                    else:
                        print(f"  â° ä¸åœ¨æœ€è¿‘ {days_back} å¤©å…§")
                    
                    # æ¯è™•ç†10å€‹ticketé¡¯ç¤ºä¸€æ¬¡é€²åº¦
                    if (i + 1) % 10 == 0:
                        print(f"  ğŸ“Š å·²è™•ç† {i+1}/{len(ticket_elements)} å€‹ ticketsï¼Œæ‰¾åˆ° {len(recent_activities)} å€‹æœ€è¿‘æ´»å‹•")
            
            print(f"\nğŸ“Š æƒæçµæœ:")
            print(f"   ç¸½å…±è™•ç†: {len(all_tickets)} å€‹ tickets")
            print(f"   æœ€è¿‘ {days_back} å¤©æ´»å‹•: {len(recent_activities)} å€‹")
            
            # ç”Ÿæˆå ±å‘Š
            self.generate_report(recent_activities, days_back, username)
            
            return True
            
        except Exception as e:
            logger.error(f"æƒæå¤±æ•—: {e}")
            return False
        
        finally:
            self.close_driver()
    
    def generate_report(self, activities, days_back, username):
        """ç”Ÿæˆå ±å‘Š"""
        try:
            print(f"\nğŸ“ ç”Ÿæˆå ±å‘Š...")
            
            # å‰µå»ºå ±å‘Šç›®éŒ„
            report_dir = "./reports"
            os.makedirs(report_dir, exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ç”Ÿæˆ JSON å ±å‘Š
            json_file = f"{report_dir}/eservice_activities_{timestamp}.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'report_date': datetime.now().isoformat(),
                    'scan_days': days_back,
                    'total_activities': len(activities),
                    'activities': activities
                }, f, ensure_ascii=False, indent=2)
            
            # å˜—è©¦ç”Ÿæˆ Gemini å‘¨å ±
            self._generate_gemini_report(json_file, report_dir, username)
            
            # ç”Ÿæˆ CSV å ±å‘Š
            csv_file = f"{report_dir}/eservice_activities_{timestamp}.csv"
            with open(csv_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['ID', 'Title', 'Date', 'Status', 'Content', 'URL', 'Source', 'Full_URL', 'Interaction_Count'])
                
                for activity in activities:
                    interaction_count = len(activity.get('detailed_interactions', []))
                    writer.writerow([
                        activity.get('id', ''),
                        activity.get('title', ''),
                        activity.get('date', ''),
                        activity.get('status', ''),
                        activity.get('content', ''),
                        activity.get('url', ''),
                        activity.get('source', ''),
                        activity.get('full_url', ''),
                        interaction_count
                    ])
            
            # ç”Ÿæˆè©³ç´°äº’å‹• CSV å ±å‘Š
            interactions_csv_file = f"{report_dir}/eservice_interactions_{timestamp}.csv"
            with open(interactions_csv_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['Ticket_ID', 'Ticket_Title', 'Interaction_Timestamp', 'Author', 'Content', 'Type', 'LTR_Content', 'Jira_Links'])
                
                for activity in activities:
                    ticket_id = activity.get('id', '')
                    ticket_title = activity.get('title', '')
                    
                    for interaction in activity.get('detailed_interactions', []):
                        # æ ¼å¼åŒ– Jira é€£çµ
                        jira_links_text = ""
                        if interaction.get('jira_links'):
                            jira_links_text = "; ".join([f"{link['ticket_id']}({link['full_url']})" for link in interaction['jira_links']])
                        
                        writer.writerow([
                            ticket_id,
                            ticket_title,
                            interaction.get('timestamp', ''),
                            interaction.get('author', ''),
                            interaction.get('content', ''),
                            interaction.get('type', ''),
                            interaction.get('ltr_content', ''),
                            jira_links_text
                        ])
            
            # ç”Ÿæˆ Jira é€£çµå°ˆç”¨ CSV å ±å‘Š
            jira_links_csv_file = f"{report_dir}/eservice_jira_links_{timestamp}.csv"
            with open(jira_links_csv_file, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['Ticket_ID', 'Ticket_Title', 'Interaction_Timestamp', 'Jira_Ticket_ID', 'Jira_Full_URL', 'Context'])
                
                for activity in activities:
                    ticket_id = activity.get('id', '')
                    ticket_title = activity.get('title', '')
                    
                    for interaction in activity.get('detailed_interactions', []):
                        for jira_link in interaction.get('jira_links', []):
                            writer.writerow([
                                ticket_id,
                                ticket_title,
                                interaction.get('timestamp', ''),
                                jira_link.get('ticket_id', ''),
                                jira_link.get('full_url', ''),
                                jira_link.get('context', '')
                            ])
            
            # ç”Ÿæˆ Markdown å ±å‘Š
            md_file = f"{report_dir}/eservice_activities_{timestamp}.md"
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(f"# eService æ´»å‹•å ±å‘Š\n\n")
                f.write(f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**æƒæç¯„åœ**: éå» {days_back} å¤©\n")
                f.write(f"**æ´»å‹•æ•¸é‡**: {len(activities)} å€‹\n\n")
                
                if activities:
                    f.write("## æ´»å‹•åˆ—è¡¨\n\n")
                    for i, activity in enumerate(activities, 1):
                        f.write(f"### {i}. {activity.get('title', 'ç„¡æ¨™é¡Œ')}\n")
                        f.write(f"- **ID**: {activity.get('id', 'N/A')}\n")
                        f.write(f"- **æ—¥æœŸ**: {activity.get('date', 'N/A')}\n")
                        f.write(f"- **ç‹€æ…‹**: {activity.get('status', 'N/A')}\n")
                        f.write(f"- **å…§å®¹**: {activity.get('content', 'N/A')}\n")
                        if activity.get('full_url'):
                            f.write(f"- **å®Œæ•´é€£çµ**: {activity.get('full_url')}\n")
                        
                        # æ·»åŠ è©³ç´°äº’å‹•å…§å®¹
                        interactions = activity.get('detailed_interactions', [])
                        if interactions:
                            f.write(f"- **äº’å‹•è¨˜éŒ„**: {len(interactions)} å€‹\n")
                            f.write("  \n")
                            f.write("  #### è©³ç´°äº’å‹•è¨˜éŒ„\n")
                            for j, interaction in enumerate(interactions, 1):
                                f.write(f"  **{j}. {interaction.get('type', 'other')}**\n")
                                f.write(f"  - æ™‚é–“: {interaction.get('timestamp', 'N/A')}\n")
                                f.write(f"  - ä½œè€…: {interaction.get('author', 'N/A')}\n")
                                f.write(f"  - å…§å®¹: {interaction.get('content', 'N/A')}\n")
                                if interaction.get('ltr_content'):
                                    f.write(f"  - **å›æ‡‰è¨Šæ¯**: {interaction.get('ltr_content', 'N/A')}\n")
                                if interaction.get('jira_links'):
                                    f.write(f"  - **Jira é€£çµ**:\n")
                                    for jira_link in interaction['jira_links']:
                                        f.write(f"    - {jira_link['ticket_id']}: {jira_link['full_url']}\n")
                                f.write("  \n")
                        else:
                            f.write("- **äº’å‹•è¨˜éŒ„**: ç„¡\n")
                        
                        f.write("\n")
                else:
                    f.write("## ç„¡æ´»å‹•è¨˜éŒ„\n\n")
                    f.write("åœ¨æŒ‡å®šæ™‚é–“ç¯„åœå…§æœªæ‰¾åˆ°ä»»ä½•æ´»å‹•è¨˜éŒ„ã€‚\n")
            
            print(f"âœ… å ±å‘Šå·²ç”Ÿæˆ:")
            print(f"   ğŸ“„ JSON: {json_file}")
            print(f"   ğŸ“Š CSV: {csv_file}")
            print(f"   ğŸ’¬ äº’å‹• CSV: {interactions_csv_file}")
            print(f"   ğŸ”— Jira é€£çµ CSV: {jira_links_csv_file}")
            print(f"   ğŸ“ Markdown: {md_file}")
            print(f"   ğŸ¤– Gemini å‘¨å ±: è«‹æŸ¥çœ‹ reports ç›®éŒ„ä¸­çš„ weekly_report_*.html æ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå ±å‘Šå¤±æ•—: {e}")
    
    def _generate_gemini_report(self, json_file, report_dir, username):
        """ä½¿ç”¨ Gemini ç”Ÿæˆå‘¨å ±"""
        try:
            # æª¢æŸ¥æ˜¯å¦æœ‰ Gemini API Key
            gemini_api_key = os.getenv('GEMINI_API_KEY')
            if not gemini_api_key:
                print("âš ï¸  æœªè¨­å®š GEMINI_API_KEY ç’°å¢ƒè®Šæ•¸ï¼Œè·³é Gemini å‘¨å ±ç”Ÿæˆ")
                print("ğŸ’¡ è«‹è¨­å®šç’°å¢ƒè®Šæ•¸: set GEMINI_API_KEY=your_api_key")
                return
            
            # å°å…¥ Gemini æœå‹™
            try:
                from gemini_service import GeminiService
            except ImportError:
                print("âš ï¸  æœªå®‰è£ google-generativeai å¥—ä»¶ï¼Œè·³é Gemini å‘¨å ±ç”Ÿæˆ")
                print("ğŸ’¡ è«‹åŸ·è¡Œ: pip install google-generativeai")
                return
            
            # åˆå§‹åŒ– Gemini æœå‹™
            try:
                gemini_service = GeminiService(gemini_api_key)
                
                # æ¸¬è©¦é€£æ¥
                if not gemini_service.test_connection():
                    print("âŒ Gemini API é€£æ¥å¤±æ•—ï¼Œè·³éå‘¨å ±ç”Ÿæˆ")
                    return
                
                # ç”Ÿæˆå‘¨å ±
                html_file = gemini_service.generate_weekly_report(json_file, report_dir, username)
                if html_file:
                    print(f"   ğŸ¤– Gemini å‘¨å ±: {html_file}")
                
            except Exception as e:
                logger.error(f"Gemini å‘¨å ±ç”Ÿæˆå¤±æ•—: {e}")
                print(f"âŒ Gemini å‘¨å ±ç”Ÿæˆå¤±æ•—: {e}")
                
        except Exception as e:
            logger.error(f"Gemini æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
            print(f"âŒ Gemini æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ” eService æ´»å‹•æƒæå’Œå ±å‘Šç”Ÿæˆå·¥å…·")
    print("="*60)
    
    # ç²å–ç”¨æˆ¶è¼¸å…¥
    username = input("è«‹è¼¸å…¥ eService å¸³è™Ÿ: ").strip()
    password = getpass.getpass("è«‹è¼¸å…¥ eService å¯†ç¢¼: ").strip()
    
    if not username or not password:
        print("âŒ å¸³è™Ÿæˆ–å¯†ç¢¼ä¸èƒ½ç‚ºç©º")
        return
    
    # è¨­å®šæƒæåƒæ•¸
    days_back = 10
    max_tickets = 50
    
    print(f"\nğŸ“‹ æƒæè¨­å®š:")
    print(f"   æƒæç¯„åœ: éå» {days_back} å¤©")
    print(f"   æœ€å¤§æƒææ•¸é‡: {max_tickets} å€‹ tickets")
    
    # ç¢ºèªé–‹å§‹
    confirm = input("\næ˜¯å¦é–‹å§‹æƒæï¼Ÿ(y/n): ").strip().lower()
    if confirm != 'y':
        print("âŒ å·²å–æ¶ˆ")
        return
    
    # é–‹å§‹æƒæ
    scanner = ActivityScanner()
    success = scanner.scan_tickets_and_generate_report(username, password, days_back, max_tickets)
    
    if success:
        print("\nâœ… æƒæå®Œæˆï¼è«‹æŸ¥çœ‹ reports ç›®éŒ„ä¸­çš„å ±å‘Šæ–‡ä»¶ã€‚")
    else:
        print("\nâŒ æƒæå¤±æ•—ï¼Œè«‹æª¢æŸ¥éŒ¯èª¤ä¿¡æ¯ã€‚")

if __name__ == "__main__":
    main()
